{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for MDC tool\n",
    "\n",
    "In this notebook, it is presented a brief tutorial on how to define and train a small Convolutional Neural Network for the classification of the MNIST Dataset. At the end of the notebook, it will be showed how to convert the keras model into the QONNX format.\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image (https://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "![alt text](images/mnist_eg.png \"MNIST example\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras (https://keras.io/) is an open source free library that gives access to an interface for Neural Networks (NN) in Python. It is now integrated into the Tensorflow library.\n",
    "With Keras we have the possibility of defining and training neural networks. QKeras (https://github.com/google/qkeras) is a quantization extension to Keras that provides drop-in replacement for some of the Keras layers, especially the ones that creates parameters and activation layers, and perform arithmetic operations, so that we can quickly create a deep quantized version of Keras network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to explore the capabilities of Qkeras, by defining and training a Convolutional Neural Network.\n",
    "First, we import the necessaries packages and do some checks on libraries versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a folder to store the outputs of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/fede/Assegno_UNISS/qonnx2mdc\n",
      "Folder 'Mnist_Training' already exists.\n",
      "/home/fede/Assegno_UNISS/qonnx2mdc/Mnist_Training\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder name\n",
    "folder_name = 'Mnist_Training'\n",
    "\n",
    "script_path = os.getcwd()\n",
    "# Get the current working directory\n",
    "current_directory = os.path.dirname(script_path)\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)\n",
    "\n",
    "\n",
    "# Create the full path to the new folder\n",
    "output_path = current_directory + \"/\" + folder_name\n",
    "\n",
    "# Check if the folder already exists\n",
    "if not os.path.exists(output_path):\n",
    "    # Create the folder\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to load the MNIST dataset, and to extract information like training size (train_size), the input shape (input__shape) and the number of classes to classify (n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_train shape: (60000, 10)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range [0, 1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape the data to add a third dimension for Conv1D\n",
    "# The Conv1D layer expects input of shape (batch_size, steps, features)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)  # 28 time steps, 28 features\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# Verify the shapes of the preprocessed data\n",
    "print(f\"x_train shape: {x_train.shape}\")  # Expected: (60000, 28, 28)\n",
    "print(f\"x_test shape: {x_test.shape}\")    # Expected: (10000, 28, 28)\n",
    "print(f\"y_train shape: {y_train.shape}\")  # Expected: (60000, 10)\n",
    "print(f\"y_test shape: {y_test.shape}\")    # Expected: (10000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to apply some preprocessing to the dataset and we manage the training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model: in this tutorial we are going to use a fixed architcture with customizable precision. In the create_qkeras_model we have to point out the input shape, the number of classes, and the quantized precisions for the layers of the model: first, the two Quantized Convolutional layers, then the Quantized Dense layer, and finally the Quantized Relu layers. The last layer, the Sigmoid activation function, wasn't quantized to preserve the accuracy. To define th eprecision of a layer, we have to define the total width and the integer width, in the format (total_width, integer_width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, MaxPooling1D, Activation, Input, BatchNormalization, GlobalAveragePooling1D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "from qkeras import QConv1D, QConv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qkeras_model(input_shape=(28, 28, 1),\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8)):\n",
    "    \"\"\"\n",
    "    Creates the QKeras model with customizable quantization parameters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input tensor.\n",
    "        num_classes (int): Number of output classes.\n",
    "        conv1_bits (tuple): (bits, integer) for the first QConv2D layer.\n",
    "        conv2_bits (tuple): (bits, integer) for the second QConv2D layer.\n",
    "        dense_bits (tuple): (bits, integer) for the QDense layer.\n",
    "        activation_bits (tuple): (bits, integer) for QActivation layers.\n",
    "\n",
    "    Returns:\n",
    "        qmodel: The QKeras model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    x = x_in = Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    x = QConv1D(\n",
    "        8, (3), name=\"q_conv1d1\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_1\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch1\")(x)\n",
    "    x = MaxPooling1D(pool_size=2, name=\"max_pool_1\")(x)\n",
    "\n",
    "########################################################################\n",
    "    # First QConv2D layer\n",
    "    x = QConv1D(\n",
    "        16, (3), name=\"q_conv1d2\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_2\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch2\")(x)\n",
    "    x = MaxPooling1D(pool_size=(2), name=\"max_pool_2\")(x)\n",
    "#####################################################################\n",
    "    x = QConv1D(\n",
    "        32, (3), name=\"q_conv1d3\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_3\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch3\")(x)\n",
    "    x = MaxPooling1D(pool_size=(2), name=\"max_pool_3\")(x)\n",
    "#############################################################################\n",
    "\n",
    "    # Flatten and Dense layer\n",
    "    x = GlobalAveragePooling1D(name=\"flatten\")(x)\n",
    "    x = QDense(\n",
    "        num_classes, name=\"q_dense\",\n",
    "        kernel_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1)\n",
    "    )(x)\n",
    "\n",
    "    # Output layer\n",
    "    x_out = Activation(\"sigmoid\", name=\"output_sigmoid\")(x)\n",
    "\n",
    "    # Create model\n",
    "    qmodel = Model(inputs=[x_in], outputs=[x_out], name=\"qkeras\")\n",
    "\n",
    "    return qmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " q_conv1d1 (QConv1D)         (None, 28, 8)             680       \n",
      "                                                                 \n",
      " act_1 (QActivation)         (None, 28, 8)             0         \n",
      "                                                                 \n",
      " batch1 (BatchNormalization)  (None, 28, 8)            32        \n",
      "                                                                 \n",
      " max_pool_1 (MaxPooling1D)   (None, 14, 8)             0         \n",
      "                                                                 \n",
      " q_conv1d2 (QConv1D)         (None, 14, 16)            400       \n",
      "                                                                 \n",
      " act_2 (QActivation)         (None, 14, 16)            0         \n",
      "                                                                 \n",
      " batch2 (BatchNormalization)  (None, 14, 16)           64        \n",
      "                                                                 \n",
      " max_pool_2 (MaxPooling1D)   (None, 7, 16)             0         \n",
      "                                                                 \n",
      " q_conv1d3 (QConv1D)         (None, 7, 32)             1568      \n",
      "                                                                 \n",
      " act_3 (QActivation)         (None, 7, 32)             0         \n",
      "                                                                 \n",
      " batch3 (BatchNormalization)  (None, 7, 32)            128       \n",
      "                                                                 \n",
      " max_pool_3 (MaxPooling1D)   (None, 3, 32)             0         \n",
      "                                                                 \n",
      " flatten (GlobalAveragePooli  (None, 32)               0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 10)                330       \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,202\n",
      "Trainable params: 3,090\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (28,28)\n",
    "qmodel = create_qkeras_model(input_shape,\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8))\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training phase can start. A low number of epochs is chosen as the model is fairly small and simple, leading to a short training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 12s 5ms/step - loss: 0.3432 - accuracy: 0.8946 - val_loss: 0.1644 - val_accuracy: 0.9464 - lr: 0.0030\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1392 - accuracy: 0.9575 - val_loss: 0.1169 - val_accuracy: 0.9610 - lr: 0.0030\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1072 - accuracy: 0.9667 - val_loss: 0.1009 - val_accuracy: 0.9656 - lr: 0.0030\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0930 - accuracy: 0.9711 - val_loss: 0.0815 - val_accuracy: 0.9749 - lr: 0.0030\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0844 - accuracy: 0.9736 - val_loss: 0.0855 - val_accuracy: 0.9732 - lr: 0.0030\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0780 - accuracy: 0.9757 - val_loss: 0.0903 - val_accuracy: 0.9712 - lr: 0.0030\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9771\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0734 - accuracy: 0.9771 - val_loss: 0.1080 - val_accuracy: 0.9625 - lr: 0.0030\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0622 - accuracy: 0.9798 - val_loss: 0.0649 - val_accuracy: 0.9785 - lr: 0.0015\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0625 - accuracy: 0.9804 - val_loss: 0.0659 - val_accuracy: 0.9785 - lr: 0.0015\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0616 - accuracy: 0.9803 - val_loss: 0.0659 - val_accuracy: 0.9795 - lr: 0.0015\n",
      "\n",
      " It took 1.6201536377271017 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "\n",
    "n_epochs = 3\n",
    "if train:\n",
    "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    qmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    # Fit the model\n",
    "    history = qmodel.fit(x_train, y_train,epochs=10,batch_size=32, validation_data=(x_test, y_test),callbacks=callbacks, verbose=1)\n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))\n",
    "\n",
    "    qmodel.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases saved to model_weights in specified format\n"
     ]
    }
   ],
   "source": [
    "# Save weights and biases for each layer in specified format\n",
    "weights_dir = \"model_weights\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "for i, layer in enumerate(qmodel.layers):\n",
    "    weights = layer.get_weights()\n",
    "    if weights:  # Only save if the layer has weights\n",
    "        layer_name = layer.__class__.__name__\n",
    "        if isinstance(layer, tf.keras.layers.Conv1D):\n",
    "            with open(os.path.join(weights_dir, f\"Conv_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef Conv_{i}_PARAMS\\n#define Conv_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define WEIGHT_Conv_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[0], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BIAS_Conv_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "        elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            with open(os.path.join(weights_dir, f\"BatchNorm_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef BatchNorm_{i}_PARAMS\\n#define BatchNorm_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define GAMMA_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[0], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BETA_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define MOVING_MEAN_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[2], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define MOVING_VARIANCE_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[3], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            with open(os.path.join(weights_dir, f\"Dense_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef Dense_{i}_PARAMS\\n#define Dense_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define WEIGHT_Dense_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[0], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BIAS_Dense_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind':lambda x: f'{x:.6f}'}).replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "\n",
    "print(f\"Weights and biases saved to {weights_dir} in specified format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the keras model can be converted into the QONNX format. The QONNX format is an exstension of ONNX, an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers (https://onnx.ai/).\n",
    "\n",
    "QONNX (Quantized ONNX), starting from ONNX, introduces three new custom operators, Quant, BipolarQuant, and Trunc, in order to represent arbitrary-precision uniform quantization in ONNX. This enables representation of binary, ternary, 3-bit, 4-bit, 6-bit or any other quantization (https://github.com/fastmachinelearning/qonnx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " q_conv1d1 (QConv2D)         (None, 28, 28, 8)         80        \n",
      "                                                                 \n",
      " act_1 (QActivation)         (None, 28, 28, 8)         0         \n",
      "                                                                 \n",
      " batch1 (BatchNormalization)  (None, 28, 28, 8)        32        \n",
      "                                                                 \n",
      " max_pool_1 (MaxPooling2D)   (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " q_conv1d2 (QConv2D)         (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " act_2 (QActivation)         (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " batch2 (BatchNormalization)  (None, 14, 14, 16)       64        \n",
      "                                                                 \n",
      " max_pool_2 (MaxPooling2D)   (None, 7, 7, 16)          0         \n",
      "                                                                 \n",
      " q_conv1d3 (QConv2D)         (None, 7, 7, 32)          4640      \n",
      "                                                                 \n",
      " act_3 (QActivation)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " batch3 (BatchNormalization)  (None, 7, 7, 32)         128       \n",
      "                                                                 \n",
      " max_pool_3 (MaxPooling2D)   (None, 3, 3, 32)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288)               0         \n",
      "                                                                 \n",
      " q_dense (QDense)            (None, 10)                2890      \n",
      "                                                                 \n",
      " output_sigmoid (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,002\n",
      "Trainable params: 8,890\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "x_train shape: (60000, 28, 28, 1), x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def create_qkeras_model(input_shape=(28, 28, 1),\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8)):\n",
    "    \"\"\"\n",
    "    Creates the QKeras model with customizable quantization parameters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input tensor.\n",
    "        num_classes (int): Number of output classes.\n",
    "        conv1_bits (tuple): (bits, integer) for the first QConv2D layer.\n",
    "        conv2_bits (tuple): (bits, integer) for the second QConv2D layer.\n",
    "        dense_bits (tuple): (bits, integer) for the QDense layer.\n",
    "        activation_bits (tuple): (bits, integer) for QActivation layers.\n",
    "\n",
    "    Returns:\n",
    "        qmodel: The QKeras model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    x = x_in = Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    x = QConv2D(\n",
    "        8, (3,3), name=\"q_conv1d1\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_1\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch1\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), name=\"max_pool_1\")(x)\n",
    "\n",
    "########################################################################\n",
    "    # First QConv2D layer\n",
    "    x = QConv2D(\n",
    "        16, (3,3), name=\"q_conv1d2\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_2\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch2\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), name=\"max_pool_2\")(x)\n",
    "#####################################################################\n",
    "    x = QConv2D(\n",
    "        32, (3,3), name=\"q_conv1d3\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_3\"\n",
    "    )(x)\n",
    "    x = BatchNormalization(name=\"batch3\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2), name=\"max_pool_3\")(x)\n",
    "#############################################################################\n",
    "\n",
    "    # Flatten and Dense layer\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = QDense(\n",
    "        num_classes, name=\"q_dense\",\n",
    "        kernel_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1)\n",
    "    )(x)\n",
    "\n",
    "    # Output layer\n",
    "    x_out = Activation(\"sigmoid\", name=\"output_sigmoid\")(x)\n",
    "\n",
    "    # Create model\n",
    "    qmodel = Model(inputs=[x_in], outputs=[x_out], name=\"qkeras\")\n",
    "\n",
    "    return qmodel\n",
    "\n",
    "\n",
    "input_shape = (28, 28, 1)  # Update input shape\n",
    "qmodel = create_qkeras_model(input_shape,\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8))\n",
    "qmodel.summary()\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to include the channel dimension (grayscale, so 1 channel)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Print shapes of the data\n",
    "print(f\"x_train shape: {x_train.shape}, x_test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 21s 10ms/step - loss: 0.1636 - accuracy: 0.9493 - val_loss: 0.0712 - val_accuracy: 0.9769 - lr: 0.0030\n",
      "\n",
      " It took 0.3473901311556498 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "\n",
    "n_epochs = 1\n",
    "if train:\n",
    "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    qmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    # Fit the model\n",
    "    history = qmodel.fit(x_train, y_train,epochs=n_epochs,batch_size=32, validation_data=(x_test, y_test),callbacks=callbacks, verbose=1)\n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))\n",
    "\n",
    "    qmodel.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion to qonnx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 12:00:01.719922: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-12-05 12:00:01.720039: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2024-12-05 12:00:01.767803: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-12-05 12:00:01.767924: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n"
     ]
    }
   ],
   "source": [
    "from qonnx.converters import from_keras\n",
    "\n",
    "path = output_path + '/qonnx_model_unige.onnx'\n",
    "print(\"conversion to qonnx...\")\n",
    "qonnx_model, _  = from_keras(\n",
    "    qmodel,\n",
    "    name=\"qkeras_to_qonnx_converted\",\n",
    "    input_signature=None,\n",
    "    opset=None,\n",
    "    custom_ops=None,\n",
    "    custom_op_handlers=None,\n",
    "    custom_rewriter=None,\n",
    "    inputs_as_nchw=None,\n",
    "    extra_opset=None,\n",
    "    shape_override=None,\n",
    "    target=None,\n",
    "    large_model=False,\n",
    "    output_path = path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
