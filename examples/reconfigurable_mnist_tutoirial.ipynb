{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for MDC tool\n",
    "\n",
    "In this notebook, it is presented a brief tutorial on how to define and train a small Convolutional Neural Network for the classification of the MNIST Dataset. At the end of the notebook, it will be showed how to convert the keras model into the QONNX format.\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image (https://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "![alt text](images/mnist_eg.png \"MNIST example\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras (https://keras.io/) is an open source free library that gives access to an interface for Neural Networks (NN) in Python. It is now integrated into the Tensorflow library.\n",
    "With Keras we have the possibility of defining and training neural networks. QKeras (https://github.com/google/qkeras) is a quantization extension to Keras that provides drop-in replacement for some of the Keras layers, especially the ones that creates parameters and activation layers, and perform arithmetic operations, so that we can quickly create a deep quantized version of Keras network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to explore the capabilities of Qkeras, by defining and training a Convolutional Neural Network.\n",
    "First, we import the necessaries packages and do some checks on libraries versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a folder to store the outputs of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder name\n",
    "folder_name = 'Mnist_Training'\n",
    "\n",
    "script_path = os.getcwd()\n",
    "# Get the current working directory\n",
    "current_directory = os.path.dirname(script_path)\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)\n",
    "\n",
    "\n",
    "# Create the full path to the new folder\n",
    "output_path = current_directory + \"/\" + folder_name\n",
    "\n",
    "# Check if the folder already exists\n",
    "if not os.path.exists(output_path):\n",
    "    # Create the folder\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to load the MNIST dataset, and to extract information like training size (train_size), the input shape (input__shape) and the number of classes to classify (n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, info = tfds.load('mnist', split='train[:90%]', with_info=True, as_supervised=True)\n",
    "ds_test = tfds.load('mnist', split='test', shuffle_files=True, as_supervised=True)\n",
    "ds_val = tfds.load('mnist', split='train[-10%:]', shuffle_files=True, as_supervised=True)\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "train_size = int(info.splits['train'].num_examples)\n",
    "input_shape = info.features['image'].shape\n",
    "n_classes = info.features['label'].num_classes\n",
    "\n",
    "print('Training on {} samples of input shape {}, belonging to {} classes'.format(train_size, input_shape, n_classes))\n",
    "fig = tfds.show_examples(ds_train, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to apply some preprocessing to the dataset and we manage the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label, nclasses=10):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(tf.squeeze(label), nclasses)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = ds_train.map(preprocess, n_classes)  # Get dataset as image and one-hot encoded labels, divided by max RGB\n",
    "train_data = train_data.shuffle(4096).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for example in train_data.take(1):\n",
    "    break\n",
    "print(\"X train batch shape = {}, Y train batch shape = {} \".format(example[0].shape, example[1].shape))\n",
    "\n",
    "val_data = ds_val.map(preprocess, n_classes)\n",
    "val_data = val_data.batch(batch_size)\n",
    "val_data = val_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# For  testing, we get the full dataset in memory as it's rather small.\n",
    "# We fetch it as numpy arrays to have access to labels and images separately\n",
    "X_test, Y_test = tfds.as_numpy(tfds.load('mnist', split='test', batch_size=-1, as_supervised=True))\n",
    "X_test, Y_test = preprocess(X_test, Y_test, nclasses=n_classes)\n",
    "print(\"X test batch shape = {}, Y test batch shape = {} \".format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the model is defined. Each layer has its own kernel_quantizers and bias_quantizers, which are functions that apply the quantization to, respectively, weights and biases of the Conv and Gemm layers, and QActivations, which quantizes the activations. While all the Relu layers are quantized, even if with different precisions for each model, we always left untouched the last activation, the Sigmoid layer, to achieve a better accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "from qkeras import QConv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "\n",
    "x = x_in = Input(shape=input_shape, name = \"input_layer\")\n",
    "\n",
    "x = QConv2D(32, (3,3), name = \"q_conv2d\", padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1))(x)\n",
    "x = QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_1\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2),name = \"max_pool_1\")(x)\n",
    "x = QConv2D(32, (3,3), name = \"q_conv2d_1\",padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1))(x)\n",
    "x = QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_2\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), name = \"max_pool_2\")(x)\n",
    "x = Flatten(name = \"flatten\")(x)\n",
    "x = QDense((10),name = \"q_dense\",kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "x_out = Activation('sigmoid', name='output_sigmoid')(x)\n",
    "\n",
    "qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training phase can start. A low number of epochs is chosen as the model is fairly small and simple, leading to a low training time. We save both the whole model and separately, its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "\n",
    "n_epochs = 3\n",
    "if train:\n",
    "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    qmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = qmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))\n",
    "\n",
    "    qmodel.save_weights(\"model_weights.h5\")\n",
    "\n",
    "    qmodel.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the keras model can be converted into the QONNX format. The QONNX format is an exstension of ONNX, an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers (https://onnx.ai/).\n",
    "\n",
    "QONNX (Quantized ONNX), starting from ONNX, introduces three new custom operators, Quant, BipolarQuant, and Trunc, in order to represent arbitrary-precision uniform quantization in ONNX. This enables representation of binary, ternary, 3-bit, 4-bit, 6-bit or any other quantization (https://github.com/fastmachinelearning/qonnx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.converters import from_keras\n",
    "\n",
    "path = output_path + '/qonnx_model_1.onnx'\n",
    "print(\"conversion to qonnx...\")\n",
    "qonnx_model, _  = from_keras(\n",
    "    qmodel,\n",
    "    name=\"qkeras_to_qonnx_converted\",\n",
    "    input_signature=None,\n",
    "    opset=None,\n",
    "    custom_ops=None,\n",
    "    custom_op_handlers=None,\n",
    "    custom_rewriter=None,\n",
    "    inputs_as_nchw=None,\n",
    "    extra_opset=None,\n",
    "    shape_override=None,\n",
    "    target=None,\n",
    "    large_model=False,\n",
    "    output_path = path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To leverage the capabilities of the MDC tool of merging different CNN models into onereconfigurable accelerator, we take the original model, change the precision of one or more layers, and freeze the others during training while fine-tuning is applied to the changed layers. This enables MDC to reuse the common, unchanged layers. In this example, we changed the precision of the second Convolutional layer (\"q_conv2d_1\") from 4 to 8 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_in = Input(shape=input_shape, name = \"input_layer\")\n",
    "\n",
    "x = QConv2D(32, (3,3), name = \"q_conv2d\", padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1))(x)\n",
    "x = QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_1\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2),name = \"max_pool_1\")(x)\n",
    "x = QConv2D(32, (3,3), name = \"q_conv2d_1\",padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1))(x)\n",
    "x = QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_2\")(x)\n",
    "x = MaxPooling2D(pool_size=(2,2), name = \"max_pool_2\")(x)\n",
    "x = Flatten(name = \"flatten\")(x)\n",
    "x = QDense((10),name = \"q_dense\",kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "    bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "x_out = Activation('sigmoid', name='output_sigmoid')(x)\n",
    "\n",
    "new_qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "new_qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the weights of the original model and freeze every layer, expect the \"q_conv2d_1\" one. AFter this operation, we can start the training of this new model: only the \"q_conv2d_1\" will be able to change the value of its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qmodel.load_weights(\"model_weights.h5\")\n",
    "\n",
    "for layer in new_qmodel.layers:\n",
    "    if layer.name != \"q_conv2d_1\":\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "\n",
    "n_epochs = 3\n",
    "if train:\n",
    "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    new_qmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = new_qmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))\n",
    "\n",
    "\n",
    "    new_qmodel.save('model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can double check if effecively the new model's weights are changed. After this chechk, we can convert also this new model into the QONNX format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the names of layers with matching and non-matching weights\n",
    "matching_layers = []\n",
    "non_matching_layers = []\n",
    "\n",
    "for original_layer, modified_layer in zip(qmodel.layers, new_qmodel.layers):\n",
    "    \n",
    "\n",
    "    # Check if the layer has weights (some layers like Dropout do not)\n",
    "    if original_layer.get_weights() and modified_layer.get_weights():\n",
    "        # Compare weights\n",
    "        weights_match = all(\n",
    "            (original_weight == modified_weight).all()\n",
    "            for original_weight, modified_weight in zip(original_layer.get_weights(), modified_layer.get_weights())\n",
    "        )\n",
    "        \n",
    "        if weights_match:\n",
    "            matching_layers.append(original_layer.name)\n",
    "        else:\n",
    "            non_matching_layers.append(original_layer.name)\n",
    "\n",
    "print(\"Layers with matching weights:\", matching_layers)\n",
    "print(\"Layers with non-matching weights:\", non_matching_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.converters import from_keras\n",
    "\n",
    "path = output_path + '/qonnx_model_2.onnx'\n",
    "print(\"conversion to qonnx...\")\n",
    "qonnx_model, _  = from_keras(\n",
    "    qmodel,\n",
    "    name=\"qkeras_to_qonnx_converted\",\n",
    "    input_signature=None,\n",
    "    opset=None,\n",
    "    custom_ops=None,\n",
    "    custom_op_handlers=None,\n",
    "    custom_rewriter=None,\n",
    "    inputs_as_nchw=None,\n",
    "    extra_opset=None,\n",
    "    shape_override=None,\n",
    "    target=None,\n",
    "    large_model=False,\n",
    "    output_path = path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
