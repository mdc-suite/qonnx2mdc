{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1D-CNN Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 10:19:36.896154: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-13 10:19:36.999387: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-13 10:19:37.521870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Shape of X_train: (16716, 300, 8)\n",
      "Shape of y_train: (16716, 6)\n",
      "Shape of y_val: (3582, 6)\n",
      "Shape of y_test: (3582, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 10:19:38.428129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:19:38.488221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:19:38.490615: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tqdm import tqdm  \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Load the data\n",
    "with open (r'/home/fede/PhD/UNIGE/Dataset_UniCa/Cagliari/dataset.npy','rb') as f:\n",
    "  X_train = np.load(f)\n",
    "  Y_train = np.load(f)\n",
    "  X_val = np.load(f)\n",
    "  Y_val = np.load(f)\n",
    "  X_test =np.load(f)\n",
    "  Y_test =np.load(f)\n",
    "  print(\"Shape of X_train:\", X_train.shape)\n",
    "  print(\"Shape of y_train:\", Y_train.shape)\n",
    "  print(\"Shape of y_val:\", Y_val.shape)\n",
    "  print(\"Shape of y_test:\", Y_test.shape)\n",
    "\n",
    "  X_train = X_train.reshape(X_train.shape[0], 1, 300, 8)\n",
    "  X_val = X_val.reshape(X_val.shape[0], 1, 300, 8)\n",
    "  X_test = X_test.reshape(X_test.shape[0], 1, 300, 8)\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "  1/262 [..............................] - ETA: 1:48 - loss: 1.8645 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 10:24:03.570735: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingradient_tape/qkeras/act_1/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 [==============================] - 1s 4ms/step - loss: 1.6518 - accuracy: 0.3245 - val_loss: 1.5080 - val_accuracy: 0.4551\n",
      "Epoch 2/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 1.4146 - accuracy: 0.5028 - val_loss: 1.3198 - val_accuracy: 0.5595\n",
      "Epoch 3/300\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 1.2418 - accuracy: 0.5776 - val_loss: 1.1693 - val_accuracy: 0.6044\n",
      "Epoch 4/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 1.1246 - accuracy: 0.6168 - val_loss: 1.0646 - val_accuracy: 0.6332\n",
      "Epoch 5/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 1.0260 - accuracy: 0.6477 - val_loss: 0.9943 - val_accuracy: 0.6572\n",
      "Epoch 6/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.9581 - accuracy: 0.6685 - val_loss: 0.9172 - val_accuracy: 0.6776\n",
      "Epoch 7/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.8946 - accuracy: 0.6904 - val_loss: 0.8742 - val_accuracy: 0.6915\n",
      "Epoch 8/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.8473 - accuracy: 0.7056 - val_loss: 0.8287 - val_accuracy: 0.7144\n",
      "Epoch 9/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.8118 - accuracy: 0.7228 - val_loss: 0.8114 - val_accuracy: 0.7141\n",
      "Epoch 10/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.7754 - accuracy: 0.7327 - val_loss: 0.7557 - val_accuracy: 0.7337\n",
      "Epoch 11/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.7496 - accuracy: 0.7384 - val_loss: 0.7282 - val_accuracy: 0.7451\n",
      "Epoch 12/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.7261 - accuracy: 0.7477 - val_loss: 0.7473 - val_accuracy: 0.7286\n",
      "Epoch 13/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.7593 - val_loss: 0.6853 - val_accuracy: 0.7560\n",
      "Epoch 14/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.6770 - accuracy: 0.7657 - val_loss: 0.6806 - val_accuracy: 0.7560\n",
      "Epoch 15/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.6596 - accuracy: 0.7739 - val_loss: 0.6666 - val_accuracy: 0.7621\n",
      "Epoch 16/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.6478 - accuracy: 0.7742 - val_loss: 0.6382 - val_accuracy: 0.7803\n",
      "Epoch 17/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.7861 - val_loss: 0.6169 - val_accuracy: 0.7853\n",
      "Epoch 18/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.6111 - accuracy: 0.7883 - val_loss: 0.6110 - val_accuracy: 0.7828\n",
      "Epoch 19/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5928 - accuracy: 0.7984 - val_loss: 0.5975 - val_accuracy: 0.7906\n",
      "Epoch 20/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5874 - accuracy: 0.7974 - val_loss: 0.5800 - val_accuracy: 0.7996\n",
      "Epoch 21/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5699 - accuracy: 0.8044 - val_loss: 0.5732 - val_accuracy: 0.7987\n",
      "Epoch 22/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5617 - accuracy: 0.8053 - val_loss: 0.5509 - val_accuracy: 0.8157\n",
      "Epoch 23/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5514 - accuracy: 0.8092 - val_loss: 0.5470 - val_accuracy: 0.8160\n",
      "Epoch 24/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5485 - accuracy: 0.8113 - val_loss: 0.5405 - val_accuracy: 0.8130\n",
      "Epoch 25/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.5263 - accuracy: 0.8208 - val_loss: 0.5381 - val_accuracy: 0.8183\n",
      "Epoch 26/300\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.5166 - accuracy: 0.8244 - val_loss: 0.5287 - val_accuracy: 0.8099\n",
      "Epoch 27/300\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.5042 - accuracy: 0.8317 - val_loss: 0.5114 - val_accuracy: 0.8283\n",
      "Epoch 28/300\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.8286 - val_loss: 0.5106 - val_accuracy: 0.8213\n",
      "Epoch 29/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4929 - accuracy: 0.8332 - val_loss: 0.4925 - val_accuracy: 0.8384\n",
      "Epoch 30/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.8354 - val_loss: 0.4923 - val_accuracy: 0.8314\n",
      "Epoch 31/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4785 - accuracy: 0.8385 - val_loss: 0.4785 - val_accuracy: 0.8381\n",
      "Epoch 32/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8447 - val_loss: 0.4742 - val_accuracy: 0.8414\n",
      "Epoch 33/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4598 - accuracy: 0.8492 - val_loss: 0.4680 - val_accuracy: 0.8462\n",
      "Epoch 34/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4557 - accuracy: 0.8478 - val_loss: 0.4785 - val_accuracy: 0.8358\n",
      "Epoch 35/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4546 - accuracy: 0.8451 - val_loss: 0.4485 - val_accuracy: 0.8490\n",
      "Epoch 36/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4446 - accuracy: 0.8521 - val_loss: 0.4505 - val_accuracy: 0.8504\n",
      "Epoch 37/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4433 - accuracy: 0.8488 - val_loss: 0.4439 - val_accuracy: 0.8504\n",
      "Epoch 38/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4402 - accuracy: 0.8515 - val_loss: 0.4664 - val_accuracy: 0.8392\n",
      "Epoch 39/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4398 - accuracy: 0.8506 - val_loss: 0.4286 - val_accuracy: 0.8573\n",
      "Epoch 40/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4339 - accuracy: 0.8512 - val_loss: 0.4341 - val_accuracy: 0.8523\n",
      "Epoch 41/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4259 - accuracy: 0.8562 - val_loss: 0.4205 - val_accuracy: 0.8604\n",
      "Epoch 42/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4177 - accuracy: 0.8611 - val_loss: 0.4221 - val_accuracy: 0.8590\n",
      "Epoch 43/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4143 - accuracy: 0.8595 - val_loss: 0.4099 - val_accuracy: 0.8699\n",
      "Epoch 44/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.4125 - accuracy: 0.8606 - val_loss: 0.4272 - val_accuracy: 0.8601\n",
      "Epoch 45/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8635 - val_loss: 0.4068 - val_accuracy: 0.8657\n",
      "Epoch 46/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.4025 - accuracy: 0.8645 - val_loss: 0.4138 - val_accuracy: 0.8593\n",
      "Epoch 47/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3972 - accuracy: 0.8670 - val_loss: 0.3942 - val_accuracy: 0.8716\n",
      "Epoch 48/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3957 - accuracy: 0.8680 - val_loss: 0.4168 - val_accuracy: 0.8571\n",
      "Epoch 49/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3878 - accuracy: 0.8704 - val_loss: 0.4001 - val_accuracy: 0.8721\n",
      "Epoch 50/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3897 - accuracy: 0.8691 - val_loss: 0.3939 - val_accuracy: 0.8680\n",
      "Epoch 51/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3839 - accuracy: 0.8724 - val_loss: 0.3920 - val_accuracy: 0.8724\n",
      "Epoch 52/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 0.3770 - val_accuracy: 0.8780\n",
      "Epoch 53/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3816 - accuracy: 0.8713 - val_loss: 0.3807 - val_accuracy: 0.8733\n",
      "Epoch 54/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3700 - accuracy: 0.8784 - val_loss: 0.3712 - val_accuracy: 0.8802\n",
      "Epoch 55/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3673 - accuracy: 0.8778 - val_loss: 0.3749 - val_accuracy: 0.8744\n",
      "Epoch 56/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3642 - accuracy: 0.8787 - val_loss: 0.3808 - val_accuracy: 0.8688\n",
      "Epoch 57/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3608 - accuracy: 0.8814 - val_loss: 0.3611 - val_accuracy: 0.8853\n",
      "Epoch 58/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3599 - accuracy: 0.8807 - val_loss: 0.3749 - val_accuracy: 0.8735\n",
      "Epoch 59/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.8837 - val_loss: 0.3501 - val_accuracy: 0.8869\n",
      "Epoch 60/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3477 - accuracy: 0.8841 - val_loss: 0.3525 - val_accuracy: 0.8917\n",
      "Epoch 61/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8835 - val_loss: 0.3470 - val_accuracy: 0.8836\n",
      "Epoch 62/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3438 - accuracy: 0.8860 - val_loss: 0.3677 - val_accuracy: 0.8730\n",
      "Epoch 63/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3513 - accuracy: 0.8824 - val_loss: 0.3619 - val_accuracy: 0.8788\n",
      "Epoch 64/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8837 - val_loss: 0.3434 - val_accuracy: 0.8897\n",
      "Epoch 65/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3436 - accuracy: 0.8847 - val_loss: 0.3564 - val_accuracy: 0.8794\n",
      "Epoch 66/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3378 - accuracy: 0.8881 - val_loss: 0.3405 - val_accuracy: 0.8869\n",
      "Epoch 67/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8892 - val_loss: 0.3566 - val_accuracy: 0.8772\n",
      "Epoch 68/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8893 - val_loss: 0.3483 - val_accuracy: 0.8858\n",
      "Epoch 69/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8891 - val_loss: 0.4105 - val_accuracy: 0.8459\n",
      "Epoch 70/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8885 - val_loss: 0.3269 - val_accuracy: 0.8945\n",
      "Epoch 71/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8930 - val_loss: 0.3349 - val_accuracy: 0.8897\n",
      "Epoch 72/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3260 - accuracy: 0.8914 - val_loss: 0.3532 - val_accuracy: 0.8780\n",
      "Epoch 73/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3259 - accuracy: 0.8909 - val_loss: 0.3543 - val_accuracy: 0.8758\n",
      "Epoch 74/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3218 - accuracy: 0.8935 - val_loss: 0.3292 - val_accuracy: 0.8934\n",
      "Epoch 75/300\n",
      "262/262 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8935 - val_loss: 0.3221 - val_accuracy: 0.8928\n",
      "Epoch 76/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3164 - accuracy: 0.8930 - val_loss: 0.3562 - val_accuracy: 0.8727\n",
      "Epoch 77/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8933 - val_loss: 0.3213 - val_accuracy: 0.8908\n",
      "Epoch 78/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.8975 - val_loss: 0.3137 - val_accuracy: 0.8959\n",
      "Epoch 79/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8964 - val_loss: 0.3270 - val_accuracy: 0.8869\n",
      "Epoch 80/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3099 - accuracy: 0.8949 - val_loss: 0.3180 - val_accuracy: 0.8903\n",
      "Epoch 81/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3081 - accuracy: 0.8975 - val_loss: 0.3074 - val_accuracy: 0.9009\n",
      "Epoch 82/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3021 - accuracy: 0.9002 - val_loss: 0.3101 - val_accuracy: 0.8964\n",
      "Epoch 83/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3029 - accuracy: 0.9011 - val_loss: 0.2990 - val_accuracy: 0.9026\n",
      "Epoch 84/300\n",
      "262/262 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9012 - val_loss: 0.3133 - val_accuracy: 0.8948\n",
      "Epoch 85/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.3001 - accuracy: 0.9011 - val_loss: 0.3185 - val_accuracy: 0.8897\n",
      "Epoch 86/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.2984 - accuracy: 0.9008 - val_loss: 0.3228 - val_accuracy: 0.8875\n",
      "Epoch 87/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.2977 - accuracy: 0.9000 - val_loss: 0.3164 - val_accuracy: 0.8939\n",
      "Epoch 88/300\n",
      "262/262 [==============================] - 1s 4ms/step - loss: 0.2979 - accuracy: 0.8988 - val_loss: 0.3174 - val_accuracy: 0.8892\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from qkeras import *\n",
    "from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "from qkeras import QConv1D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Define a 1D Convolutional Neural Network (CNN) class\n",
    "class CNN_1D():\n",
    "    # Initialize the class with training, validation, and test datasets\n",
    "    def __init__(self,\n",
    "                 X_train,\n",
    "                 y_train,\n",
    "                 X_val,\n",
    "                 y_val,\n",
    "                 X_test,\n",
    "                 y_test):\n",
    "        # Model configuration: filters, kernels, batch size, epochs, learning rate, and classes\n",
    "        self.filters = [[8], [16],[32]]  # Different filter sizes for Conv1D layers\n",
    "        self.kernels = [2, 3, 4, 5]  # Different kernel sizes for Conv1D layers\n",
    "        self.batch_size = 64  # Number of samples per gradient update\n",
    "        self.epochs = 300  # Number of training epochs\n",
    "        self.learning_rate = 0.001  # Learning rate for the optimizer\n",
    "        self.n_classes = 6  # Number of output classes\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)  # Optimizer configuration\n",
    "        self.loss = 'categorical_crossentropy'  # Loss function for classification\n",
    "        self.metrics = ['accuracy']  # Evaluation metric to track\n",
    "        # Callbacks for early stopping to prevent overfitting\n",
    "        self.callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    "                         # Option to add learning rate scheduling (commented out)\n",
    "\n",
    "        # Assign the training, validation, and testing data\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "        # Automatically start training upon initialization\n",
    "        #self.model = self.train()\n",
    "        self.model = self.train_q()\n",
    "\n",
    "    # Internal method to create the CNN model with the specified filters and kernel sizes\n",
    "    def __create_model(self, filters, kernel, n_classes, verbose=1):\n",
    "        model = tf.keras.models.Sequential()  # Sequential model for a linear stack of layers\n",
    "        for i, f in enumerate(filters):\n",
    "            if i == 0:\n",
    "                # First Conv1D layer with input shape specified\n",
    "                model.add(tf.keras.layers.Conv1D(f, kernel, activation='relu', input_shape=(self.X_train.shape[1:]), padding='same'))\n",
    "            else:\n",
    "                # Additional Conv1D layers\n",
    "                model.add(tf.keras.layers.Conv1D(f, kernel, activation='relu', padding='same'))\n",
    "            model.add(tf.keras.layers.BatchNormalization())  # Batch normalization to stabilize learning\n",
    "            model.add(tf.keras.layers.MaxPooling1D(2))  # Max pooling to reduce dimensionality\n",
    "        model.add(tf.keras.layers.GlobalAveragePooling1D())  # Global average pooling layer\n",
    "        # Output dense layer with softmax activation for classification\n",
    "        model.add(tf.keras.layers.Dense(n_classes, activation='softmax'))\n",
    "        if verbose:\n",
    "            model.summary()  # Print the model architecture if verbose is enabled\n",
    "        return model\n",
    "\n",
    "\n",
    "    def create_qmodel(self):\n",
    "    \n",
    "        x = x_in = Input(shape= self.X_train.shape[1:], name = \"input_layer\")\n",
    "\n",
    "        x = QConv1D(32, 3, name = \"q_conv2d\", padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "            bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1))(x)\n",
    "        x = QActivation(quantized_relu(bits=8, integer=4, use_sigmoid=0, negative_slope=0.0), name=\"act_1\")(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = MaxPooling1D(pool_size=2,name = \"max_pool_1\")(x)\n",
    "        x = GlobalAveragePooling1D()(x)        \n",
    "        x = QDense((6),name = \"q_dense\",kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "            bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "        x_out = Activation('softmax', name='output_sigmoid')(x)\n",
    "\n",
    "        model = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "        return model\n",
    "    def create_qmodel_2d(self):\n",
    "    \n",
    "        x = x_in = Input(shape= self.X_train.shape[1:], name = \"input_layer\")\n",
    "\n",
    "        x = QConv2D(32, (1, 3), name = \"q_conv2d\", padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "            bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1))(x)\n",
    "        x = QActivation(quantized_relu(bits=8, integer=4, use_sigmoid=0, negative_slope=0.0), name=\"act_1\")(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=(1, 2),name = \"max_pool_1\")(x)\n",
    "        x = GlobalAveragePooling2D()(x)        \n",
    "        x = QDense((6),name = \"q_dense\",kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "            bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "        x_out = Activation('softmax', name='output_sigmoid')(x)\n",
    "\n",
    "        model = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "        return model\n",
    "    def train_q(self):\n",
    "        \n",
    "        qmodel = self.create_qmodel_2d()\n",
    "        initial_optimizer_config = self.optimizer.get_config()\n",
    "        optimizer = type(self.optimizer).from_config(initial_optimizer_config)  # Reset optimizer for each iteration\n",
    "        qmodel.compile(optimizer=optimizer, loss=self.loss, metrics=self.metrics)\n",
    "        qmodel.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, \n",
    "                                        validation_data=(self.X_val, self.y_val), callbacks=self.callbacks, verbose=1)\n",
    "        return qmodel\n",
    "\n",
    "    # Train the CNN model using different combinations of filters and kernels\n",
    "    def train(self):\n",
    "        with tf.device('/GPU:0'):\n",
    "            best_val_acc = 0  # Variable to track the best validation accuracy\n",
    "            best_f = None  # To store the best filter configuration\n",
    "            best_k = None  # To store the best kernel size\n",
    "\n",
    "            # Save initial optimizer state to reuse across models\n",
    "            initial_optimizer_config = self.optimizer.get_config()\n",
    "\n",
    "            # Progress bar to display training progress across filter and kernel combinations\n",
    "            with tqdm(total=len(self.filters) * len(self.kernels), desc=\"Training Progress\", unit=\"iteration\") as pbar:\n",
    "                for f in self.filters:  # Iterate through each filter configuration\n",
    "                    for k in self.kernels:  # Iterate through each kernel size\n",
    "                        # Create and compile the model\n",
    "                        model = self.__create_model(f, k, self.n_classes, verbose=0)\n",
    "                        optimizer = type(self.optimizer).from_config(initial_optimizer_config)  # Reset optimizer for each iteration\n",
    "                        model.compile(optimizer=optimizer, loss=self.loss, metrics=self.metrics)\n",
    "                        \n",
    "                        # Train the model on the training data and validate on validation data\n",
    "                        history = model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.batch_size, \n",
    "                                            validation_data=(self.X_val, self.y_val), callbacks=self.callbacks, verbose=0)\n",
    "                        \n",
    "                        # If the current model's validation accuracy is the best, save it\n",
    "                        if history.history['val_accuracy'][-1] > best_val_acc:\n",
    "                            best_val_acc = history.history['val_accuracy'][-1]  # Update best validation accuracy\n",
    "                            model.save(f\"model_{f}_{k}.h5\")  # Save the model\n",
    "                            best_f = f  # Track best filter configuration\n",
    "                            best_k = k  # Track best kernel size\n",
    "                        pbar.update(1)  # Update the progress bar\n",
    "            \n",
    "            # Load the best model based on validation accuracy\n",
    "            best_model = tf.keras.models.load_model(f\"model_{best_f}_{best_k}.h5\")\n",
    "\n",
    "            # Evaluate the best model on training, validation, and testing datasets\n",
    "            _, train_accuracy = best_model.evaluate(self.X_train, self.y_train, verbose=0)\n",
    "            _, test_accuracy = best_model.evaluate(self.X_test, self.y_test, verbose=0)\n",
    "            _, val_accuracy = best_model.evaluate(self.X_val, self.y_val, verbose=0)\n",
    "\n",
    "            # Print the best filter/kernel configuration and accuracies\n",
    "            print(f\"best_f: {best_f}, best_k: {best_k}\")\n",
    "            print(\"Best model\")\n",
    "            best_model.summary()  # Print the best model architecture\n",
    "            print(\"Train_accuracy:\", train_accuracy, \"Val accuracy:\", val_accuracy, \"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "            return best_model\n",
    "\n",
    "model = CNN_1D(X_train, Y_train, X_val, Y_val, X_test, Y_test)  # Initialize the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300, 8)\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "correct: [[[ 0.7900269  -0.2052717   0.37117046 ...  0.04761182 -0.5583706\n",
      "    0.82216614]\n",
      "  [ 0.71108395 -0.22226508  0.38408306 ...  0.1047499  -0.6087973\n",
      "    0.78123355]\n",
      "  [ 0.5852255  -0.4416051   0.01506689 ...  0.12277777 -0.751336\n",
      "    0.6398249 ]\n",
      "  ...\n",
      "  [-0.9766554  -1.3084828   0.8872643  ...  0.523307   -1.5926337\n",
      "   -0.55269796]\n",
      "  [-0.9770108  -1.1471397   0.5630894  ...  0.5061585  -1.604404\n",
      "   -0.5892323 ]\n",
      "  [-0.98310006 -0.8659002   1.1277664  ...  0.5107626  -1.4530728\n",
      "   -0.5460629 ]]]\n",
      "QKeras Output: [[3.2729098e-08 2.5301863e-02 5.4793265e-03 2.2767908e-05 4.2709418e-02\n",
      "  9.2648661e-01]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "\n",
    "# Load the input data from the C++ test file\n",
    "input_data = np.loadtxt(\"/home/fede/test_input_data.txt\", dtype=np.float32)\n",
    "\n",
    "# Reshape to match QKeras input shape\n",
    "NUM_FEATURES = 8  # Same as in C++\n",
    "WINDOW_SIZE = 300\n",
    "\n",
    "input_data = input_data.reshape(1, 1, WINDOW_SIZE, NUM_FEATURES)  # Shape: (1, 300, 8)\n",
    "#input_data1 = X_train[102].reshape(1, 1, WINDOW_SIZE, NUM_FEATURES) \n",
    "\n",
    "\n",
    "print(X_train[0].shape)\n",
    "# Run the model with the same input\n",
    "#output_qkeras = model.model.predict(X_train[0])\n",
    "output_qkeras = model.model.predict(X_train[2:3])  # Keeps batch dimension (1, 1, 300, 8)\n",
    "\n",
    "print(\"correct:\", X_train[2])\n",
    "\n",
    "# Print results\n",
    "max = 0\n",
    "\n",
    "    \n",
    "print(\"QKeras Output:\", output_qkeras)\n",
    "correct_class = np.argmax(Y_train[0])  \n",
    "print(correct_class)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "sample n: 77\n",
      "[[[ 1.3198973   0.43553346 -0.48278418 ... -1.0238531   0.1940515\n",
      "   -0.7256301 ]\n",
      "  [ 1.3007689   0.42590395 -0.02840268 ... -0.8660884   0.38284305\n",
      "   -0.47496957]\n",
      "  [ 1.3269824   0.06821638 -0.7948421  ... -0.8538679  -0.03489642\n",
      "   -0.45548582]\n",
      "  ...\n",
      "  [ 1.6323969   0.51933026 -1.4022009  ... -1.8409101  -0.55843925\n",
      "   -2.2259157 ]\n",
      "  [ 1.6515054   0.74563575 -1.1497234  ... -1.9835336   0.09736931\n",
      "   -1.7994627 ]\n",
      "  [ 1.5731585   0.73989815 -0.628648   ... -1.9172432   0.58965504\n",
      "   -1.0549612 ]]]\n",
      "QKeras Output: [[9.5840979e-01 3.9589211e-02 1.4513045e-03 5.4628152e-04 5.1536841e-08\n",
      "  3.3792917e-06]]\n",
      "correct class: 0\n",
      "Reshaped data saved to /home/fede/reshaped_input_vitis.txt\n"
     ]
    }
   ],
   "source": [
    "def reshape_and_save_input(X_sample, output_file):\n",
    "    # X_sample should have shape (300, 8), which is (timestep, features)\n",
    "    X_sample = np.squeeze(X_sample)\n",
    "    assert X_sample.shape == (300, 8), f\"Expected shape (300, 8), but got {X_sample.shape}\"\n",
    "\n",
    "    # Reshape (300, 8) to (1, 8, 1, 300) for Vitis HLS model\n",
    "    reshaped_data = np.transpose(X_sample)  # Transpose from (300, 8) to (8, 300)\n",
    "    reshaped_data = reshaped_data.flatten()  # Flatten to a single 1D array (2400 elements)\n",
    "\n",
    "    # Save reshaped data to a text file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for value in reshaped_data:\n",
    "            f.write(f\"{value}\\n\")\n",
    "\n",
    "    print(f\"Reshaped data saved to {output_file}\")\n",
    "\n",
    "\n",
    "sample_n = 77\n",
    "\n",
    "output_qkeras = model.model.predict(X_train[sample_n:sample_n + 1])  # Keeps batch dimension (1, 1, 300, 8)\n",
    "\n",
    "print(\"sample n:\", sample_n)\n",
    "print( X_train[sample_n])\n",
    "\n",
    "    \n",
    "print(\"QKeras Output:\", output_qkeras)\n",
    "correct_class = np.argmax(Y_train[sample_n])  \n",
    "print(\"correct class:\",correct_class)  \n",
    "X_sample = X_train[sample_n]  # Select the first sample (shape: (300, 8))\n",
    "\n",
    "# File to save reshaped input\n",
    "output_file = \"/home/fede/reshaped_input_vitis.txt\"\n",
    "\n",
    "# Call function to reshape and save input data\n",
    "reshape_and_save_input(X_sample, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1112\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:1090\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_env/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[1;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[0;32m-> 2254\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_env/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_env/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Save weights and biases for each layer in the specified format\n",
    "weights_dir = \"model_weights_q\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "for i, layer in enumerate(model.model.layers):\n",
    "    weights = layer.get_weights()\n",
    "    if weights:  # Only save if the layer has weights\n",
    "        layer_name = layer.__class__.__name__\n",
    "        if isinstance(layer, tf.keras.layers.Conv1D) :\n",
    "            with open(os.path.join(weights_dir, f\"Conv_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef Conv_{i}_PARAMS\\n#define Conv_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define WEIGHT_Conv_{i} \")\n",
    "                # Transpose the weights to match [depth][height][width][kernel]\n",
    "                # weights[0] shape is [filter_height, input_channels, output_channels]\n",
    "                # We need to transpose it to [input_channels, filter_height, 1, output_channels]\n",
    "                \n",
    "                weight_array = np.transpose(weights[0], (1, 0, 2))  # [depth][height][1][kernel]\n",
    "                print(weights)\n",
    "                f.write(\"{\" + np.array2string(weight_array, separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BIAS_Conv_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "        elif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            with open(os.path.join(weights_dir, f\"BatchNorm_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef BatchNorm_{i}_PARAMS\\n#define BatchNorm_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define GAMMA_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[0], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BETA_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define MOVING_MEAN_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[2], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define MOVING_VARIANCE_BatchNorm_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[3], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            with open(os.path.join(weights_dir, f\"Dense_{i}_params.h\"), \"w\") as f:\n",
    "                f.write(f\"#ifndef Dense_{i}_PARAMS\\n#define Dense_{i}_PARAMS\\n\\n\")\n",
    "                f.write(f\"#define WEIGHT_Dense_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[0], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#define BIAS_Dense_{i} \")\n",
    "                f.write(\"{\" + np.array2string(weights[1], separator=', ', formatter={'float_kind': lambda x: f'{x:.6f}'} , threshold=np.inf)[1:-1].replace('[', '{').replace(']', '}').replace('\\n', '') + \"}\\n\")\n",
    "                f.write(f\"#endif\\n\")\n",
    "\n",
    "print(f\"Weights and biases saved to {weights_dir} in specified format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion to qonnx...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-13 10:47:36.295631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.296795: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-02-13 10:47:36.296905: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2025-02-13 10:47:36.297198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.298302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.299356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.300435: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.301611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.302674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6166 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-13 10:47:36.317405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.318609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.319644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.320785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.321922: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.322990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6166 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2025-02-13 10:47:36.324761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.325853: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2025-02-13 10:47:36.325913: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2025-02-13 10:47:36.326171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.327270: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.328330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.329433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.330458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-13 10:47:36.331514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6166 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from qonnx.converters import from_keras\n",
    "\n",
    "output_path = '/home/fede/PhD/UNIGE/ONNX'\n",
    "\n",
    "path = output_path + '/qonnx_model_unige.onnx'\n",
    "print(\"conversion to qonnx...\")\n",
    "qonnx_model, _  = from_keras(\n",
    "    model.model,\n",
    "    name=\"qkeras_to_qonnx_converted\",\n",
    "    input_signature=None,\n",
    "    opset=None,\n",
    "    custom_ops=None,\n",
    "    custom_op_handlers=None,\n",
    "    custom_rewriter=None,\n",
    "    inputs_as_nchw=None,\n",
    "    extra_opset=None,\n",
    "    shape_override=None,\n",
    "    target=None,\n",
    "    large_model=False,\n",
    "    output_path = path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
